{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries and mounting google drive."
      ],
      "metadata": {
        "id": "VqjNQ5yJUldz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rih7t3XuMq64"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting google drive to access documents\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1ODcirpOIUZ",
        "outputId": "101dbf38-cb7d-4ad2-f235-6807906d973d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing text"
      ],
      "metadata": {
        "id": "ZuZnMMEjZNeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing function to clean and tokenize text\n",
        "def preprocess(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())"
      ],
      "metadata": {
        "id": "6H-6x5OsMwke"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Documents and Queries"
      ],
      "metadata": {
        "id": "GpAT9fjDZWAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load documents from the provided folder path\n",
        "def load_documents(folder_path):\n",
        "    docs = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
        "                docs[filename] = preprocess(file.read())\n",
        "    return docs"
      ],
      "metadata": {
        "id": "KRtxNgD6M1_g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading queries from the provided query file\n",
        "def load_queries(query_file_path):\n",
        "    with open(query_file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]"
      ],
      "metadata": {
        "id": "7L4rcDYqM5_x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing Term Frequencies and Document Frequencies"
      ],
      "metadata": {
        "id": "hwQsfK11ZaVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing term frequencies and document frequencies for each word in the documents\n",
        "def compute_statistics(docs):\n",
        "    doc_count = len(docs)\n",
        "    term_doc_freq = defaultdict(int) #Counting how many docs contain each term\n",
        "    term_freq = defaultdict(lambda: defaultdict(int)) #Counting term frequency in each document\n",
        "\n",
        "    for doc_id, words in docs.items():\n",
        "        word_set = set(words) #Getting unique words in the document\n",
        "        for word in words:\n",
        "            term_freq[doc_id][word] += 1 #Counting occurrences of each word\n",
        "        for word in word_set:\n",
        "            term_doc_freq[word] += 1 #Counting how many documents contain the word\n",
        "\n",
        "    return term_freq, term_doc_freq, doc_count"
      ],
      "metadata": {
        "id": "ht5wobpaM-Ql"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing Relevance Probabilities using Binary Independence Model (BIM)"
      ],
      "metadata": {
        "id": "GXyzbkz8Zssu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute relevance probabilities using BIM\n",
        "def compute_relevance_prob(query, term_freq, term_doc_freq, doc_count):\n",
        "    scores = {}\n",
        "    for doc_id in term_freq:\n",
        "        score = 1.0 #Initializing score for each document\n",
        "        for term in query:\n",
        "            tf = term_freq[doc_id].get(term, 0) #Getting term frequency in the document\n",
        "            df = term_doc_freq.get(term, 0) #Getting document frequency of the term\n",
        "            #Calculating probability of the term being relevant\n",
        "            p_term_given_relevant = (tf + 1) / (sum(term_freq[doc_id].values()) + len(term_doc_freq))\n",
        "            #Calculating probability of the term being non-relevant\n",
        "            p_term_given_not_relevant = (df + 1) / (doc_count - df + len(term_doc_freq))\n",
        "            score *= (p_term_given_relevant / p_term_given_not_relevant) #Updating document score\n",
        "        scores[doc_id] = score\n",
        "    return scores"
      ],
      "metadata": {
        "id": "Xbo4ul0-NAmz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Retrieving and Ranking Documents"
      ],
      "metadata": {
        "id": "f4cTL6DIZwXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving documents based on queries and ranking them by relevance scores\n",
        "def retrieve_documents(folder_path, query_file_path):\n",
        "    docs = load_documents(folder_path)\n",
        "    queries = load_queries(query_file_path)\n",
        "\n",
        "    term_freq, term_doc_freq, doc_count = compute_statistics(docs)\n",
        "\n",
        "    for query in queries:\n",
        "        query_terms = preprocess(query)  # Tokenizing the query\n",
        "        scores = compute_relevance_prob(query_terms, term_freq, term_doc_freq, doc_count)\n",
        "        ranked_docs = sorted(scores.items(), key=lambda item: item[1], reverse=True)  # Ranking docs by score\n",
        "\n",
        "        # Printing top 3 ranked documents in a specified format\n",
        "        print(f\"Top 3 Relevance Scores for query {query}:\")\n",
        "        for rank, (doc_id, score) in enumerate(ranked_docs[:3], 1):\n",
        "            print(f\"Rank {rank}: {doc_id}, Score: {score:.4f}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "Wje2jwEFNCNd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example usage to retrieve documents based on queries\n",
        "folder_path = '/content/drive/MyDrive/dataset/Hotels of Nepal'\n",
        "query_file_path = '/content/drive/MyDrive/dataset/query.txt'\n",
        "retrieve_documents(folder_path, query_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5eF9_erNDnD",
        "outputId": "93478146-b017-4f34-daab-194d2cb365f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Relevance Scores for query “luxury hotel Nepal”:\n",
            "Rank 1: Hotel yak and Yeti.txt, Score: 0.0151\n",
            "Rank 2: The Dwarika's Hotel.txt, Score: 0.0073\n",
            "Rank 3: Gokarna Forest Resort.txt, Score: 0.0068\n",
            "\n",
            "Top 3 Relevance Scores for query “family-friendly stay”:\n",
            "Rank 1: Hotel Lake Shore.txt, Score: 0.0669\n",
            "Rank 2: Hyatt Regency Kathmandu.txt, Score: 0.0624\n",
            "Rank 3: Flying Yak Kathmandu.txt, Score: 0.0516\n",
            "\n",
            "Top 3 Relevance Scores for query “budget hotel Kathmandu”:\n",
            "Rank 1: The Dwarika's Hotel.txt, Score: 0.1447\n",
            "Rank 2: Shangri-La Hotel.txt, Score: 0.1350\n",
            "Rank 3: Hyatt Regency Kathmandu.txt, Score: 0.1088\n",
            "\n",
            "Top 3 Relevance Scores for query “mountain view accommodation”:\n",
            "Rank 1: Hotel Grand Holiday.txt, Score: 0.1494\n",
            "Rank 2: Hotel Middle Path & Spa.txt, Score: 0.0245\n",
            "Rank 3: Hotel Fewa Dream.txt, Score: 0.0217\n",
            "\n",
            "Top 3 Relevance Scores for query “hotel rooftop restaurant”:\n",
            "Rank 1: Hotel Grand Holiday.txt, Score: 0.1649\n",
            "Rank 2: Hotel Lake Shore.txt, Score: 0.0301\n",
            "Rank 3: Hotel Middle Path & Spa.txt, Score: 0.0263\n",
            "\n",
            "Top 3 Relevance Scores for query “hotel spa services”:\n",
            "Rank 1: The Dwarika's Hotel.txt, Score: 0.0261\n",
            "Rank 2: Shangri-La Hotel.txt, Score: 0.0209\n",
            "Rank 3: Temple Tree Resort & Spa.txt, Score: 0.0172\n",
            "\n",
            "Top 3 Relevance Scores for query “pet-friendly hotel”:\n",
            "Rank 1: The Dwarika's Hotel.txt, Score: 0.3177\n",
            "Rank 2: Hotel Roadhouse.txt, Score: 0.2876\n",
            "Rank 3: Hotel Lake Shore.txt, Score: 0.2732\n",
            "\n",
            "Top 3 Relevance Scores for query “hotel near Thamel”:\n",
            "Rank 1: The Dwarika's Hotel.txt, Score: 0.1587\n",
            "Rank 2: Hotel Roadhouse.txt, Score: 0.1436\n",
            "Rank 3: Flying Yak Kathmandu.txt, Score: 0.1405\n",
            "\n",
            "Top 3 Relevance Scores for query “airport shuttle service”:\n",
            "Rank 1: Flying Yak Kathmandu.txt, Score: 0.0393\n",
            "Rank 2: Temple Tree Resort & Spa.txt, Score: 0.0167\n",
            "Rank 3: Hotel Middle Path & Spa.txt, Score: 0.0102\n",
            "\n",
            "Top 3 Relevance Scores for query “boutique hotel Pokhara”:\n",
            "Rank 1: Hotel Lake Shore.txt, Score: 0.1694\n",
            "Rank 2: Temple Tree Resort & Spa.txt, Score: 0.1556\n",
            "Rank 3: Hotel Grand Holiday.txt, Score: 0.1550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Assigning and Saving Random Relevance Scores"
      ],
      "metadata": {
        "id": "zkMf1zgbZ2X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#Assigning random relevance scores (0 for irrelevant, 1 for relevant)\n",
        "def assign_random_relevance(queries, documents, relevance_scale=(0, 1)):\n",
        "    relevance_scores = {}\n",
        "\n",
        "    for query in queries:\n",
        "        relevance_scores[query] = {}  #Initializing relevance score dictionary for the query\n",
        "        for doc in documents:\n",
        "            #Assigning a random relevance score (between 0 and 1 by default)\n",
        "            relevance_scores[query][doc] = random.randint(relevance_scale[0], relevance_scale[1])\n",
        "\n",
        "    return relevance_scores\n",
        "\n",
        "#Saving the relevance scores to a file\n",
        "def save_relevance_scores_to_file(relevance_scores, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        for query, doc_scores in relevance_scores.items():\n",
        "            for doc, score in doc_scores.items():\n",
        "                f.write(f\"{query},{doc},{score}\\n\")  #Saving as query,document,score format\n",
        "\n",
        "\n",
        "#Example usage to assign random relevance scores and saving them to a file\n",
        "folder_path = '/content/drive/MyDrive/dataset/Hotels of Nepal'\n",
        "query_file_path = '/content/drive/MyDrive/dataset/query.txt'\n",
        "\n",
        "#Loading documents and queries\n",
        "documents = load_documents(folder_path)  #Returning a dictionary of document_id -> content\n",
        "queries = load_queries(query_file_path)  #Returning a list of queries\n",
        "\n",
        "#Randomly assigning relevance scores (0 = irrelevant, 1 = relevant)\n",
        "random_relevance_scores = assign_random_relevance(queries, documents.keys())\n",
        "\n",
        "#Saving the relevance scores to query_relevance_score.txt\n",
        "output_file = 'query_relevance_score.txt'\n",
        "save_relevance_scores_to_file(random_relevance_scores, output_file)\n",
        "\n",
        "print(f\"Relevance scores saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXuuB0rtW3Cn",
        "outputId": "3c419ab7-4969-45b5-c7e2-6ea4cff08ffa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevance scores saved to query_relevance_score.txt\n"
          ]
        }
      ]
    }
  ]
}